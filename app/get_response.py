import openai
import os

class OpenAIClient:
    def __init__(self, api_key=None):
        """
        Initialize the OpenAI client.
        
        Args:
            api_key (str, optional): API key for OpenAI. If not provided, uses the one from the notebook.
        """
        if api_key is None:
            # Default API key from notebook if not provided
            api_key = "glhf_73f6b8fadcfa7adf7070ef3fff8f2e75"
            
        self.client = openai.OpenAI(
            api_key=api_key,
            base_url="https://glhf.chat/api/openai/v1"
        )
        
    def get_response(self, user_prompt, system_prompt, chat_history=None):
        """
        Sends a request to the API with the user prompt and returns the response.
        
        Args:
            user_prompt (str): The prompt to send to the LLM.
            system_prompt (str): The system prompt to guide the LLM.
            chat_history (list, optional): List of previous messages in the conversation.
            
        Returns:
            str: The response generated by the LLM, or an error message.
        """
        try:
            messages = []
            
            # Add system prompt
            messages.append({"role": "system", "content": system_prompt})
            
            # Add chat history if provided
            if chat_history:
                for message in chat_history:
                    messages.append(message)
            
            # Add current user prompt
            messages.append({"role": "user", "content": user_prompt})
            
            completion = self.client.chat.completions.create(
                model="hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
                messages=messages
            )
            
            response_text = completion.choices[0].message.content
            return response_text
        
        except Exception as e:
            return f"An error occurred while generating the response: {str(e)}" 